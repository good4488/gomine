{
 "metadata": {
  "name": "",
  "signature": "sha256:fd5bcae686d60edb9fc9c912d7e827a8dceeaa14f1b341c9f56a5804d06c5c52"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from mining_script import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/qorwns/textmining/data/160922_test/   path    exist!\n",
        "/home/qorwns/textmining/data/160922_test/raw_text/   path    exist!\n",
        "/home/qorwns/textmining/data/160922_test/full_text/   path    exist!\n",
        "/home/qorwns/textmining/data/160922_test/Output/   path    exist!\n",
        "/home/qorwns/textmining/data/160922_test/tokens/   path    exist!\n",
        "/home/qorwns/textmining/data/160922_test/TFIDF/   path    exist!\n",
        "/home/qorwns/textmining/data/160922_test/ONLYTF/   path    exist!\n",
        "/home/qorwns/textmining/data/160922_test/RAKE_keywords/   path    exist!\n",
        "Directory setting OK...\n",
        "\n",
        "In list_time, 2253 file inputs!\n",
        "PubMed used\n",
        "PubMed starting index = 0\n",
        "Making Corpus End......"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "TFIDF matrix shape is"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(2977, 13855)\n",
        "The number of TFIDF unique word set is\n",
        "13855\n",
        "ONLYTF matrix shape is"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(2977, 13855)\n",
        "The number of ONLYTF unique word set is\n",
        "13855\n",
        "Run_time =  241.172530"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "JOB DONE\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "man_keyword_list = keyword_pubmed\n",
      "\n",
      "man_index_list=[]\n",
      "for i, key in enumerate(man_keyword_list):\n",
      "    if key:\n",
      "        man_index_list.append(i)\n",
      "        \n",
      "## keyword_pubmed : keywords from mining script code\n",
      "## man_index_list : \uc804\uccb4 \ub17c\ubb38 2977\uac1c \uc911\uc5d0\uc11c, \ud0a4\uc6cc\ub4dc \uc139\uc158\uc774 \uc788\ub294 \ub17c\ubb38\ub4e4\uc758 index\n",
      "\n",
      "sents= []\n",
      "for i in man_index_list:\n",
      "    sent = ''\n",
      "    for word in man_keyword_list[i]:\n",
      "        sent = sent+word+' '\n",
      "    sents.append(sent)\n",
      "    \n",
      "    \n",
      "total_sents=[]\n",
      "for j in sents:\n",
      "    tokens = get_tokens(j)\n",
      "    pos_token = nltk.pos_tag(tokens)\n",
      "    filtered_tokens = [word for word in pos_token if not word[0] in stop_words]\n",
      "    lemma_first = lemmatize_tokens_for_pos(filtered_tokens, lemmatizer)\n",
      "    lemmatized_tokens = [word for word in lemma_first if not word in stop_words]\n",
      "    remove_num = [word for word in lemmatized_tokens if word>'a'  and word.isalnum() and not word[0].isdigit()]\n",
      "    #stemming = stem_tokens(remove_num, stemmer)\n",
      "    final_word = []\n",
      "    for word in remove_num:\n",
      "        if len(word) == 2:\n",
      "            #if not is_useful_2gram(word):\n",
      "                #continue\n",
      "            #else:\n",
      "            final_word.append(word)\n",
      "        else:\n",
      "            final_word.append(word)\n",
      "            \n",
      "    total_sents.append(final_word)\n",
      "\n",
      "print(len(total_sents))\n",
      "man_keyword = total_sents\n",
      "\n",
      "## man_keyword : \uc804\ucc98\ub9ac \uc644\ub8cc\ub41c Manual assigned keywords"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "895\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "key_length_list =  [len(words) for words in man_keyword]\n",
      "print('Mean keyword length ',np.mean(key_length_list))\n",
      "## key_length_list : \ub17c\ubb38 \ubcc4 \ud0a4\uc6cc\ub4dc \uac2f\uc218"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Mean keyword length  10.2782122905\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import collections\n",
      "total_man_words = [i for word in man_keyword for i in word]\n",
      "count=[]\n",
      "count.extend(collections.Counter(total_man_words).most_common(len(total_man_words)))\n",
      "print('len keywords',len(count))\n",
      "\n",
      "unique_keyword = []\n",
      "for i, item in enumerate(count):\n",
      "    unique_keyword.append(item[0])\n",
      "\n",
      "dictionary = dict()\n",
      "for word, _ in count:\n",
      "    dictionary[word] = len(dictionary)\n",
      "reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
      "    \n",
      "print(dictionary['metal'])\n",
      "print(reverse_dictionary[0])\n",
      "## dictionary : \ub2e8\uc5b4\ub97c \ub123\uc73c\uba74 index \ubc18\ud658\n",
      "## reverse_dictionary : index \ub123\uc73c\uba74 \ub2e8\uc5b4\ub97c \ubc18\ud658"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "len keywords 1637\n",
        "0\n",
        "metal\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "new_key = []\n",
      "for i in man_index_list:\n",
      "    a = [TFIDF_total_word[index] for index in list(target_keyword_10[i])]\n",
      "    new_key.append(a)\n",
      "com_keyword_TFIDF = new_key\n",
      "\n",
      "new_key = []\n",
      "for i in man_index_list:\n",
      "    a = [TFIDF_total_word[index] for index in list(target_keyword_TF_10[i])]\n",
      "    new_key.append(a)\n",
      "com_keyword_ONLYTF = new_key\n",
      "\n",
      "print('man keyword',man_keyword[-1])\n",
      "print('TFIDF keyword',com_keyword_TFIDF[-1])\n",
      "print('ONLYTF keyword',com_keyword_ONLYTF[-1])\n",
      "## com_keyword_ONLYTF : TF model\ub85c \uc5bb\uc740 \ud0a4\uc6cc\ub4dc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "man keyword ['cdmofs', 'curcumin', 'encapsulation', 'spectroscopy', 'stability', 'cyclodextrin']\n",
        "TFIDF keyword ['interaction', 'cdmof', 'complex', 'cdmofs', 'cd', 'emittance', 'ph', 'cyclodextrin', 'benign', 'curcumin']\n",
        "ONLYTF keyword ['interaction', 'complex', 'cdmofs', 'stability', 'metal', 'organic', 'cyclodextrin', 'ph', 'curcumin', 'group']\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def past_paper_find(target_paper_index, key_list):\n",
      "    for i, paper in enumerate(man_keyword[:target_paper_index]):\n",
      "        test = []\n",
      "        for word in key_list:\n",
      "            test.append(word in paper)\n",
      "        \n",
      "        if all(test):\n",
      "            print(i, paper)\n",
      "            \n",
      "            \n",
      "def past_index_find(target_paper_index, key_list):\n",
      "    index_list=[]\n",
      "    for i, paper in enumerate(man_keyword[:target_paper_index]):\n",
      "        test = []\n",
      "        for word in key_list:\n",
      "            test.append(word in paper)\n",
      "            \n",
      "        if all(test):\n",
      "            index_list.append(i)\n",
      "    return index_list\n",
      "\n",
      "## past_paper_find : \ud2b9\uc815 index\ubcf4\ub2e4 \uc774\uc804 index\uc5d0\uc11c, \uadf8 \ub2e8\uc5b4\ub4e4\uc774 \uacf5\ud1b5\uc73c\ub85c \ub4f1\uc7a5\ud55c \ub17c\ubb38 \ucd9c\ub825\n",
      "## past_index_find : \uc704\uc640 \uac19\uc740\ub370 \uadf8 index\ub4e4\uc758 \ub9ac\uc2a4\ud2b8 \ubc18\ud658"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "past_paper_find(397, ['tcnq'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "169 ['tcnq', 'dianion', 'magnetic', 'property', 'metal', 'organic', 'framework', 'transition', 'metal']\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "intersections=np.zeros((len(man_keyword),len(man_keyword)))\n",
      "for i in range(len(man_keyword)):\n",
      "    for j in range(len(man_keyword)):\n",
      "        intersections[i,j] = len(set(man_keyword[i])&set(man_keyword[j]))\n",
      "        \n",
      "## intersections : \ud2b9\uc815 \ub17c\ubb38 i, j\uc758 \ud0a4\uc6cc\ub4dc \uad50\uc9d1\ud569\uc758 \uc6d0\uc18c \uac2f\uc218\ub97c \ub098\ud0c0\ub0b8 \ud589\ub82c"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def find_combination_candidate(file_index, keywords):\n",
      "    key_list = man_keyword[file_index]\n",
      "    test = []\n",
      "    for key_index, key in enumerate(keywords):\n",
      "        index = past_index_find(file_index,[key])\n",
      "        if index:\n",
      "            cos = [ intersections[i,file_index] for i in index ]\n",
      "            cos, index = (list(t) for t in zip(*sorted(zip(cos, index), reverse=True)))\n",
      "            test.append(index[0])\n",
      "        else:\n",
      "            test.append([])\n",
      "        \n",
      "    if all(test):\n",
      "        for i in test:\n",
      "            print(i, man_keyword[i])\n",
      "        return test\n",
      "    \n",
      "## find_combination_candidate : \ud2b9\uc815 \ub17c\ubb38\uc758 \ud0a4\uc6cc\ub4dc \uac01\uac01\uc774 \uc5b4\ub514\uc11c \uc654\ub294\uc9c0 \ucd94\uce21"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def find_cite_candidate(file_index, intersect_num):\n",
      "    key_list = list(set(man_keyword[file_index]))\n",
      "    test = []\n",
      "    if intersect_num==0:\n",
      "        intersect_num = len(key_list)\n",
      "    if intersect_num==-1:\n",
      "        intersect_num = len(key_list) - 1\n",
      "    if intersect_num==-2:\n",
      "        intersect_num = len(key_list) - 2\n",
      "    for key_index, key in enumerate(key_list):\n",
      "        index = past_index_find(file_index,[key])\n",
      "        if index:\n",
      "            cos = [ intersections[i,file_index] for i in index ]\n",
      "            cos, index = (list(t) for t in zip(*sorted(zip(cos, index), reverse=True)))\n",
      "            test.append(index[0])\n",
      "        \n",
      "    if len(test) >= intersect_num:\n",
      "        #for i in test:\n",
      "            #print(i, man_keyword[i])\n",
      "        return test\n",
      "    \n",
      "## find_cite_candidate : \ud0a4\uc6cc\ub4dc \uac2f\uc218\ub97c \uc9c0\uc815\ud574\uc11c, \uadf8 \ud0a4\uc6cc\ub4dc \uac2f\uc218\ub9cc\ud07c \uc77c\uce58\ud558\ub294 \uac83\uc744 \ucc3e\uc74c\n",
      "## Option\uc774 \uc788\ub294\ub370, 0\uc744 \uc785\ub825\ud558\uba74 \uadf8 \ub17c\ubb38\uc758 \ubaa8\ub4e0 \ud0a4\uc6cc\ub4dc\uac00 \uacfc\uac70\uc5d0 \ub098\uc640\uc57c \ubc18\ud658\n",
      "##                 -1\uc744 \uc785\ub825\ud558\uba74 \ud558\ub098\uc758 \uc0c8\ub85c\uc6b4 \ud0a4\uc6cc\ub4dc \ud5c8\uc6a9"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "candi = dict()\n",
      "for i in range(len(man_keyword)):\n",
      "    if find_cite_candidate(i,0):\n",
      "        candi[i] = find_cite_candidate(i,0)\n",
      "    if i%100==0:\n",
      "        print('total candidates before %d'%i,len(candi))\n",
      "        \n",
      "print('total candidates before 895',len(candi))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "total candidates before 0 0\n",
        "total candidates before 100"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4\n",
        "total candidates before 200"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 23\n",
        "total candidates before 300"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 47\n",
        "total candidates before 400"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 65\n",
        "total candidates before 500"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 98\n",
        "total candidates before 600"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 128\n",
        "total candidates before 700"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 163\n",
        "total candidates before 800"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 205\n",
        "total candidates before 895"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 230\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_length = int(len(man_keyword)/2)\n",
      "train_set = man_keyword[:train_length]\n",
      "test_set = man_keyword[train_length:]\n",
      "\n",
      "# train_set : 447\uac1c\n",
      "# test_set : 448\uac1c"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "total_man_words = [i for word in train_set for i in word]\n",
      "count_train=[]\n",
      "count_train.extend(collections.Counter(total_man_words).most_common(len(total_man_words)))\n",
      "print('len keywords',len(count_train))\n",
      "\n",
      "unique_keyword = []\n",
      "for i, item in enumerate(count_train):\n",
      "    unique_keyword.append(item[0])\n",
      "\n",
      "dictionary = dict()\n",
      "for word, _ in count_train:\n",
      "    dictionary[word] = len(dictionary)\n",
      "reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
      "    \n",
      "print(dictionary['metal'])\n",
      "print(reverse_dictionary[0])\n",
      "## dictionary : \ub2e8\uc5b4\ub97c \ub123\uc73c\uba74 index \ubc18\ud658\n",
      "## reverse_dictionary : index \ub123\uc73c\uba74 \ub2e8\uc5b4\ub97c \ubc18\ud658"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "len keywords 1049\n",
        "0\n",
        "metal\n"
       ]
      }
     ],
     "prompt_number": 82
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def build_paper_matrix(index):\n",
      "    matrix = np.zeros((len(unique_keyword),len(unique_keyword)), dtype=np.int16)\n",
      "    col_list = [dictionary[word] for word in train_set[index]]\n",
      "    #print(col_list)\n",
      "    for j in col_list:\n",
      "        for k in col_list:\n",
      "            matrix[j,k] += 1\n",
      "    return matrix"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 83
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def find_maximum_fscore(idea):\n",
      "    max_f = 0\n",
      "    max_index = 0\n",
      "    for i, key in enumerate(test_set):\n",
      "        inter = set(key)&set(idea)\n",
      "        p = len(inter)/len(key)\n",
      "        r = len(inter)/len(idea)\n",
      "        try:\n",
      "            f_one = 2*p*r/(p+r)\n",
      "        except ZeroDivisionError:\n",
      "            f_one = 0.0\n",
      "\n",
      "        if max_f < f_one:\n",
      "            max_f = f_one\n",
      "            max_index = i\n",
      "            \n",
      "    return max_f, max_index\n",
      "\n",
      "\n",
      "def graph_model_one():\n",
      "    find_num = 0\n",
      "    hit_num = 0\n",
      "    hit_index = []\n",
      "    candidate = []\n",
      "    matrix = build_paper_matrix(0)\n",
      "    for i in range(1, len(train_set)):\n",
      "        matrix += build_paper_matrix(i)\n",
      "    # test_set updated\n",
      "    \n",
      "    print(matrix)\n",
      "    iteration = 100000\n",
      "    window = 10\n",
      "    \n",
      "    for i in range(iteration):\n",
      "        idea = []\n",
      "        word_index = 0\n",
      "        col_list = matrix[word_index].nonzero()[0]\n",
      "        df = matrix[word_index, word_index]\n",
      "        col = [matrix[word_index,t] for t in col_list if t >  word_index]\n",
      "        ind_list = [t for t in col_list if t > word_index]\n",
      "        if window:\n",
      "            col = np.array(col[:window])\n",
      "        else:\n",
      "            col = np.array(col)\n",
      "        idea.append(reverse_dictionary[word_index])\n",
      "        while all([df != 1, len(idea) <= 10]):\n",
      "            if prob_based_index(col) == None:\n",
      "                break\n",
      "            word_index = ind_list[prob_based_index(col)]\n",
      "            col_list = matrix[word_index].nonzero()[0]\n",
      "            df = matrix[word_index,word_index]\n",
      "            col= [matrix[word_index,t] for t in col_list if t > word_index]\n",
      "            ind_list = [t for t in col_list if t > word_index]\n",
      "            if window:\n",
      "                col= np.array(col[:window])\n",
      "            else:\n",
      "                col= np.array(col)\n",
      "            idea.append(reverse_dictionary[word_index])\n",
      "        \n",
      "        max_f, max_index = find_maximum_fscore(idea)\n",
      "        if max_f >= 0.8:\n",
      "            print('new_idea',idea)\n",
      "            print('test_set',test_set[max_index])\n",
      "            print('test set index',max_index)\n",
      "            print('fscore',max_f)\n",
      "            print('')\n",
      "            hit_num += 1\n",
      "            hit_index.append(max_index)\n",
      "        \n",
      "    print('hit num is',hit_num)\n",
      "    print('total hit percent is',len(set(hit_index))/len(test_set)*100,'%')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 98
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_set[264]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 102,
       "text": [
        "['chiral',\n",
        " 'stationary',\n",
        " 'phase',\n",
        " 'enantioseparation',\n",
        " 'high',\n",
        " 'performance',\n",
        " 'liquid',\n",
        " 'chromatography',\n",
        " 'metal',\n",
        " 'organic',\n",
        " 'framework',\n",
        " 'racemates']"
       ]
      }
     ],
     "prompt_number": 102
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "graph_model_one()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[474 432 433 ...,   2   1   1]\n",
        " [432 453 426 ...,   0   1   1]\n",
        " [433 426 435 ...,   0   1   1]\n",
        " ..., \n",
        " [  2   0   0 ...,   1   0   0]\n",
        " [  1   1   1 ...,   0   1   0]\n",
        " [  1   1   1 ...,   0   0   1]]\n",
        "new_idea"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " ['metal', 'framework', 'organic', 'phase', 'chromatography', 'high', 'liquid', 'stationary', 'chiral', 'enantioseparation', 'isomer']\n",
        "test_set ['chiral', 'stationary', 'phase', 'enantioseparation', 'high', 'performance', 'liquid', 'chromatography', 'metal', 'organic', 'framework', 'racemates']\n",
        "test set index 264\n",
        "fscore 0.8695652173913043\n",
        "\n",
        "new_idea"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " ['metal', 'framework', 'organic', 'phase', 'chromatography', 'high', 'liquid', 'stationary', 'chiral', 'atropisomers']\n",
        "test_set ['chiral', 'stationary', 'phase', 'enantioseparation', 'high', 'performance', 'liquid', 'chromatography', 'metal', 'organic', 'framework', 'racemates']\n",
        "test set index 264\n",
        "fscore 0.8181818181818182\n",
        "\n",
        "new_idea"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " ['metal', 'framework', 'organic', 'adsorption', 'carbon', 'separation', 'dioxide', 'ligand', 'host', 'design', 'zirconium']\n",
        "test_set ['adsorption', 'carbon', 'dioxide', 'fixation', 'host', 'guest', 'ligand', 'design', 'metal', 'organic', 'framework']\n",
        "test set index 314\n",
        "fscore 0.8181818181818182\n",
        "\n",
        "new_idea"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " ['metal', 'framework', 'organic', 'adsorption', 'carbon', 'porous', 'dioxide', 'ligand', 'host', 'design', 'zirconium']\n",
        "test_set ['adsorption', 'carbon', 'dioxide', 'fixation', 'host', 'guest', 'ligand', 'design', 'metal', 'organic', 'framework']\n",
        "test set index 314\n",
        "fscore 0.8181818181818182\n",
        "\n",
        "new_idea"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " ['metal', 'framework', 'organic', 'adsorption', 'carbon', 'porous', 'dioxide', 'guest', 'host', 'design', 'icosahedral']\n",
        "test_set ['adsorption', 'carbon', 'dioxide', 'fixation', 'host', 'guest', 'ligand', 'design', 'metal', 'organic', 'framework']\n",
        "test set index 314\n",
        "fscore 0.8181818181818182\n",
        "\n",
        "new_idea"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " ['metal', 'framework', 'organic', 'adsorption', 'sensor', 'guest', 'host', 'ligands', 'citric']\n",
        "test_set ['adsorption', 'host', 'guest', 'metal', 'organic', 'framework', 'sensitizer', 'sensor']\n",
        "test set index 15\n",
        "fscore 0.823529411764706\n",
        "\n",
        "new_idea"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " ['metal', 'organic', 'gas', 'phase', 'chromatography', 'stationary', 'capillary', 'enantioseparation', 'tubular', 'column']\n",
        "test_set ['capillary', 'column', 'gas', 'chromatography', 'metal', 'organic', 'framework', 'stationary', 'phase']\n",
        "test set index 289\n",
        "fscore 0.8421052631578948\n",
        "\n",
        "hit num is"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7\n",
        "total hit percent is 0.8928571428571428 %\n"
       ]
      }
     ],
     "prompt_number": 99
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def graph_model_random():\n",
      "    iteration = 100000\n",
      "    find_num = 0\n",
      "    hit_num = 0\n",
      "    hit_index = []\n",
      "    for i in range(iteration):\n",
      "        new = set()\n",
      "        while len(new) < 10:\n",
      "            new.add(rn.randint(0,len(unique_keyword)-1))\n",
      "        new = list(new)\n",
      "        idea = [reverse_dictionary[index] for index in new]\n",
      "\n",
      "        max_f, max_index = find_maximum_fscore(idea)\n",
      "        \n",
      "        if max_f >= 0.8:\n",
      "            print('new_idea',idea)\n",
      "            print('test_set',test_set[max_index])\n",
      "            print('index',max_index)\n",
      "            print('fscore',max_f)\n",
      "            print('')\n",
      "            hit_num += 1\n",
      "            hit_index.append(max_index)\n",
      "    \n",
      "    print('hit num is',hit_num)\n",
      "    print('total hit percent is',len(set(hit_index))/iteration*100,'%')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 94
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "graph_model_random()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "hit num is 0\n",
        "total hit percent is 0.0 %\n"
       ]
      }
     ],
     "prompt_number": 93
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class MDP:\n",
      "    def __init__(self, init, actlist, terminals, gamma = 0.9):\n",
      "        update(self, init=init, actlist=actlist, terminals=terminals, gamma=gamma, states=set(), reward={})\n",
      "    \n",
      "    def Reward(self, state):\n",
      "        return self.reward[state]\n",
      "    \n",
      "    def Transition(self, action):\n",
      "        abstract\n",
      "        \n",
      "    def Actions(self, state):\n",
      "        if state in self.terminals:\n",
      "            return [None]\n",
      "        else:\n",
      "            return self.actlist"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class WordMDP(MDP):\n",
      "    def __init__(self, grid, terminals, init=(0,0), gamma=0.9):\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "past_paper_find(448, ['column'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "96 ['gas', 'chromatography', 'metal', 'organic', 'framework', 'open', 'tubular', 'column', 'separation', 'stationary', 'phase']\n"
       ]
      }
     ],
     "prompt_number": 70
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}